{
 "metadata": {
  "name": "",
  "signature": "sha256:855fb03b88c1f0d260b28ac9f700e4ed64050c8a035fd029a753b3853e51d53c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib qt4\n",
      "from __future__ import division\n",
      "\n",
      "from models import tools, optimize, models, filters\n",
      "from models.tests import PerformanceTest\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn as sk\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = tools.load_data(offset=1700000, limit=500000)\n",
      "data = data[filters.usa_states(data)]\n",
      "#data = tools.unknown_answers(data)\n",
      "print len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "31006\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elo_test = PerformanceTest(models.EloModel(), data, split_data=True)\n",
      "elo_test.run()\n",
      "elo_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "RMSE: 0.401072157963\n",
        "AUC: 0.761769439159\n",
        "OFF: -0.00320089485118\n",
        "CORRECT: 1987\n",
        "ACCURACY: 0.771650485437\n",
        "Set Size: 2575"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elot_test = PerformanceTest(models.EloResponseTime(), data, split_data=True)\n",
      "elot_test.run()\n",
      "elot_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "RMSE: 0.419755451333\n",
        "AUC: 0.734505173408\n",
        "OFF: -0.0359641950947\n",
        "CORRECT: 17177\n",
        "ACCURACY: 0.737052134735\n",
        "Set Size: 23305"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfa_test = PerformanceTest(models.PFAModel(models.EloModel()), data)\n",
      "pfa_test.run()\n",
      "pfa_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "RMSE: 0.378762640406\n",
        "AUC: 0.795581771756\n",
        "OFF: 0.0129000311924\n",
        "CORRECT: 24584\n",
        "ACCURACY: 0.792878797652\n",
        "Set Size: 31006"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfag_test = PerformanceTest(models.PFAGong(models.EloModel(), gamma=1.5, delta=-0.2, decay=0.8), data)\n",
      "pfag_test.run()\n",
      "pfag_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "RMSE: 0.383440850163\n",
        "AUC: 0.787201009454\n",
        "OFF: 0.0250953456438\n",
        "CORRECT: 24499\n",
        "ACCURACY: 0.790137392763\n",
        "Set Size: 31006"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfaf_test = PerformanceTest(models.PFAForgetting(models.EloModel()), data)\n",
      "pfaf_test.run()\n",
      "pfaf_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "RMSE: 0.384352375631\n",
        "AUC: 0.770040105839\n",
        "OFF: 0.0441200371592\n",
        "CORRECT: 24571\n",
        "ACCURACY: 0.794021651317\n",
        "Set Size: 30945"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfas_test = PerformanceTest(models.PFASpacing(models.EloModel(), iota=1.5, decay_rate=0.18), data)\n",
      "pfas_test.run()\n",
      "pfas_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "RMSE: 0.377471537896\n",
        "AUC: 0.79583708885\n",
        "OFF: 0.0199368217543\n",
        "CORRECT: 24598\n",
        "ACCURACY: 0.793330323163\n",
        "Set Size: 31006"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfast_test = PerformanceTest(models.PFAStaircase(models.EloModel(), staircase={(-np.inf, np.inf): 5}), data)\n",
      "pfast_test.run()\n",
      "pfast_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "0.33809650378991235"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpr, tpr, thresholds = sk.metrics.roc_curve(\n",
      "    pfag_test.train_values['observed'],\n",
      "    pfag_test.train_values['predicted'], pos_label=1)\n",
      "plt.plot(fpr, tpr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fca9543cd50>]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positives = []\n",
      "negatives = []\n",
      "p = pfa_test.train_values[pfa_test.train_values['observed'] == 1]\n",
      "n = pfa_test.train_values[pfa_test.train_values['observed'] == 0]\n",
      "\n",
      "intervals = zip(np.arange(0, 0.99, 0.01), np.arange(0.01, 1, 0.01))\n",
      "for lower, upper in intervals:\n",
      "    positive_count = len(p[(p['predicted'] > lower) & (p['predicted'] < upper)])\n",
      "    negative_count = len(n[(n['predicted'] > lower) & (n['predicted'] < upper)])\n",
      "    positives.append(positive_count)\n",
      "    negatives.append(negative_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot([np.mean(interval) for interval in intervals], positives, 'g-')\n",
      "plt.plot([np.mean(interval) for interval in intervals], negatives, 'r-')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f1b0015b0d0>]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
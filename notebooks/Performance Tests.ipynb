{
 "metadata": {
  "name": "",
  "signature": "sha256:a610ab1527633d7eeb45d29bea38fd94e0356f2a6dc4b78c3a617346d832e2ea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib qt4\n",
      "from __future__ import division\n",
      "\n",
      "from models import tools, optimize, models\n",
      "from models.tests import PerformanceTest\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = tools.load_data('../data/answers_all.csv', offset=1900000, limit=50000)\n",
      "#data = data[data['number_of_options'] == 0]\n",
      "#data = tools.unknown_answers(data)\n",
      "print len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "50000\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elo = models.EloModel()\n",
      "#elo_test = PerformanceTest(elo, data)\n",
      "#elo_test.run()\n",
      "#print str(elo_test.rmse()) + '\\n' + str(elo_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elot = models.EloResponseTime()\n",
      "elot_test = PerformanceTest(elot, data)\n",
      "elot_test.run()\n",
      "print str(elot_test.rmse()) + '\\n' + str(elot_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.395484212707\n",
        "Training Set Size: 1392\n",
        "AUC: 0.761178225205\n",
        "Training Set Size: 1392\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfa = models.PFAModel(elo)\n",
      "pfa_test = PerformanceTest(pfa, data)\n",
      "pfa_test.run()\n",
      "print str(pfa_test.rmse()) + '\\n' + str(pfa_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.346703397122\n",
        "Training Set Size: 8492\n",
        "AUC: 0.933671069749\n",
        "Training Set Size: 8492\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "fpr, tpr, thresholds = metrics.roc_curve(pfa_test.y_true, pfa_test.y_pred, pos_label=1)\n",
      "plt.plot(fpr, tpr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f9094c67210>]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfas = models.PFASpacing(elo, decay_rate=0.18, tau=2)\n",
      "pfas_test = PerformanceTest(pfas, data)\n",
      "pfas_test.run()\n",
      "print str(pfas_test.rmse()) + '\\n' + str(pfas_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.340402920792\n",
        "Training Set Size: 8492\n",
        "AUC: 0.956092459166\n",
        "Training Set Size: 8492\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpr, tpr, thresholds = metrics.roc_curve(pfas_test.y_true, pfas_test.y_pred, pos_label=1)\n",
      "plt.plot(fpr, tpr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f3593415cd0>]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfat = models.PFATiming(elo, time_effect_fun=lambda t: 1.6 - 0.1*np.log(t))\n",
      "pfat_test = PerformanceTest(pfat, data)\n",
      "pfat_test.run()\n",
      "print str(pfat_test.results['train'].rmse) + '\\n' + str(pfat_test.results['train'].auc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.366514440568\n",
        "0.772063802573\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def chunks(l, n):\n",
      "    for i in xrange(0, len(l), n):\n",
      "        yield l[i:i+n]\n",
      "\n",
      "def interval_error(test, interval_size=500):\n",
      "    answers = []\n",
      "    for id, row in test.train_set.iterrows():\n",
      "        item = test.model.items.get((row.user_id, row.place_id))\n",
      "        if item is not None and item.practices:\n",
      "            diff = tools.to_datetime(item.practices[-1]) - tools.to_datetime(row.inserted)\n",
      "            answers += [(int(diff.total_seconds()), [row.is_correct, row.predicted])]\n",
      "   \n",
      "    answers = sorted(answers, key=lambda p: p[0])\n",
      "\n",
      "    get_diffs = lambda c: [diff for diff, _ in c]\n",
      "    get_answers = lambda c: [ans for _, ans in c]\n",
      "\n",
      "    intervals = {\n",
      "        (min(get_diffs(chunk)), max(get_diffs(chunk))): get_answers(chunk)\n",
      "        for chunk in chunks(answers, interval_size)\n",
      "    }\n",
      "    \n",
      "    return intervals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intervals = interval_error(pfat_test, interval_size=1500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = []\n",
      "for interval, d in intervals.items():\n",
      "    d = np.array(d)\n",
      "    result.append((\n",
      "        sum(interval) / 2.,\n",
      "        sum(d[:, 0] - d[:, 1]) / len(d),\n",
      "    ))\n",
      "result = sorted(result, key=lambda x: x[0])\n",
      "\n",
      "plt.plot([x[0] for x in result], [x[1] for x in result])\n",
      "plt.xscale('log')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intervals.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[(305, 402),\n",
        " (-1, 0),\n",
        " (78790, 85885),\n",
        " (163, 224),\n",
        " (171892, 177343),\n",
        " (992, 1394),\n",
        " (9890, 42624),\n",
        " (42639, 78770),\n",
        " (90355, 171890),\n",
        " (107, 163),\n",
        " (52, 107),\n",
        " (224, 305),\n",
        " (0, 0),\n",
        " (724, 992),\n",
        " (2050, 3247),\n",
        " (402, 533),\n",
        " (533, 724),\n",
        " (0, 52),\n",
        " (85889, 90349),\n",
        " (3247, 4732),\n",
        " (4732, 9888),\n",
        " (1394, 2049)]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "metadata": {
  "name": "",
  "signature": "sha256:0ce93c0249816b70d53e4bfcedb317548e7b50e95a3f9e8596f74d25f12fc8bb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib qt4\n",
      "from __future__ import division\n",
      "\n",
      "from models import tools, optimize, models\n",
      "from models.tests import PerformanceTest\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn as sk\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = tools.load_data(offset=1700000, limit=100000)\n",
      "data = data[data['number_of_options'] == 0]\n",
      "#data = tools.unknown_answers(data)\n",
      "print len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "65671\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elo_test = PerformanceTest(models.EloModel(), data, split_data=True)\n",
      "elo_test.run()\n",
      "elo_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "RMSE: 0.412190567636\n",
        "AUC: 0.741612278807\n",
        "OFF: -0.00971289802897\n",
        "CORRECT: 17422\n",
        "ACCURACY: 0.747564900236\n",
        "Set Size: 23305"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elot_test = PerformanceTest(models.EloResponseTime(), data, split_data=True)\n",
      "elot_test.run()\n",
      "elot_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "RMSE: 0.419755451333\n",
        "AUC: 0.734505173408\n",
        "OFF: -0.0359641950947\n",
        "CORRECT: 17177\n",
        "ACCURACY: 0.737052134735\n",
        "Set Size: 23305"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfa_test = PerformanceTest(models.PFAModel(models.EloModel()), data)\n",
      "pfa_test.run()\n",
      "pfa_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "RMSE: 0.32457498692\n",
        "AUC: 0.854420069745\n",
        "OFF: -0.0116913051164\n",
        "CORRECT: 56424\n",
        "ACCURACY: 0.859192033013\n",
        "Set Size: 65671"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfag_test = PerformanceTest(models.PFAGong(models.EloModel(), gamma=1.5, delta=0., decay=0.6), data)\n",
      "pfag_test.run()\n",
      "pfag_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "RMSE: 0.322995910897\n",
        "AUC: 0.857309380267\n",
        "OFF: -0.00107370518367\n",
        "CORRECT: 56502\n",
        "ACCURACY: 0.860379771893\n",
        "Set Size: 65671"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfaf_test = PerformanceTest(models.PFAForgetting(models.EloModel()), data)\n",
      "pfaf_test.run()\n",
      "pfaf_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "RMSE: 0.322885970426\n",
        "AUC: 0.853318576917\n",
        "OFF: 0.00657295075453\n",
        "CORRECT: 56506\n",
        "ACCURACY: 0.86301641848\n",
        "Set Size: 65475"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfas_test = PerformanceTest(models.PFASpacing(models.EloModel(), iota=1.5, decay_rate=0.25), data)\n",
      "pfas_test.run()\n",
      "pfas_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "RMSE: 0.324206301353\n",
        "AUC: 0.859554199011\n",
        "OFF: -0.0171890426757\n",
        "CORRECT: 56428\n",
        "ACCURACY: 0.859252942699\n",
        "Set Size: 65671"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfast_test = PerformanceTest(models.PFAStaircase(models.EloModel(), staircase={(-np.inf, np.inf): 5}), data)\n",
      "pfast_test.run()\n",
      "pfast_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "0.33809650378991235"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpr, tpr, thresholds = sk.metrics.roc_curve(\n",
      "    pfag_test.train_values['observed'],\n",
      "    pfag_test.train_values['predicted'], pos_label=1)\n",
      "plt.plot(fpr, tpr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fca9543cd50>]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positives = []\n",
      "negatives = []\n",
      "p = pfaf_test.train_values[pfaf_test.train_values['observed'] == 1]\n",
      "n = pfaf_test.train_values[pfaf_test.train_values['observed'] == 0]\n",
      "\n",
      "intervals = zip(np.arange(0, 0.99, 0.01), np.arange(0.01, 1, 0.01))\n",
      "for lower, upper in intervals:\n",
      "    positive_count = len(p[(p['predicted'] > lower) & (p['predicted'] < upper)])\n",
      "    negative_count = len(n[(n['predicted'] > lower) & (n['predicted'] < upper)])\n",
      "    positives.append(positive_count)\n",
      "    negatives.append(negative_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot([np.mean(interval) for interval in intervals], positives, 'g-')\n",
      "plt.plot([np.mean(interval) for interval in intervals], negatives, 'r-')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fca94e5a4d0>]"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
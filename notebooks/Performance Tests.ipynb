{
 "metadata": {
  "name": "",
  "signature": "sha256:671215e7ec651495f4b820931a9e222f35966d2571e3b64f0244acf7088ff750"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib qt4\n",
      "from __future__ import division\n",
      "\n",
      "from models import tools, optimize, models\n",
      "from models.tests import PerformanceTest\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = tools.load_data('../data/answers_train.csv', limit=15000)\n",
      "#data = data[data['number_of_options'] == 0]\n",
      "#data = tools.unknown_answers(data)\n",
      "print len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15000\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elo = models.EloModel()\n",
      "#elo_test = PerformanceTest(elo, data)\n",
      "#elo_test.run()\n",
      "#print str(elo_test.rmse()) + '\\n' + str(elo_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elot = models.EloResponseTime()\n",
      "elot_test = PerformanceTest(elot, data)\n",
      "elot_test.run()\n",
      "print str(elot_test.rmse()) + '\\n' + str(elot_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.395484212707\n",
        "Training Set Size: 1392\n",
        "AUC: 0.761178225205\n",
        "Training Set Size: 1392\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfa = models.PFAModel(elo)\n",
      "pfa_test = PerformanceTest(pfa, data)\n",
      "pfa_test.run()\n",
      "print str(pfa_test.rmse()) + '\\n' + str(pfa_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.264179030279\n",
        "Training Set Size: 9718\n",
        "AUC: 0.799771339249\n",
        "Training Set Size: 9718\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfas = models.PFASpacing(elo, decay_rate=0.2, spacing_rate=0)\n",
      "pfas_test = PerformanceTest(pfas, data)\n",
      "pfas_test.run()\n",
      "print str(pfas_test.rmse()) + '\\n' + str(pfas_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.256326511787\n",
        "Training Set Size: 9718\n",
        "AUC: 0.808176681747\n",
        "Training Set Size: 9718\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfasa = models.PFASpacingAlt(elo, decay_rate=0.15, spacing_rate=0.2)\n",
      "pfasa_test = PerformanceTest(pfasa, data)\n",
      "pfasa_test.run()\n",
      "print str(pfasa_test.rmse()) + '\\n' + str(pfasa_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.258277999348\n",
        "Training Set Size: 9718\n",
        "AUC: 0.803818505947\n",
        "Training Set Size: 9718\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfat = models.PFATiming(elo, time_effect_fun=lambda t: 1.6 - 0.1*np.log(t))\n",
      "pfat_test = PerformanceTest(pfat, data)\n",
      "pfat_test.run()\n",
      "print str(pfat_test.rmse()) + '\\n' + str(pfat_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.256088320337\n",
        "Training Set Size: 9718\n",
        "AUC: 0.817059730417\n",
        "Training Set Size: 9718\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def get_interval(number, intervals):\n",
      "    for left, right in intervals:\n",
      "        if left <= number <= right:\n",
      "            return (left, right)\n",
      "    raise LookupError\n",
      "\n",
      "def interval_error(test, intervals):\n",
      "    error = defaultdict(lambda: (0, 0, 0))\n",
      "    for id, row in test.test_set.iterrows():\n",
      "        item = test.model.items.get((row.user_id, row.place_id))\n",
      "        if item is not None and item.practices:\n",
      "            to_datetime = test.model.to_datetime\n",
      "            diff = to_datetime(row.inserted) - to_datetime(item.practices[-1])\n",
      "            interval = get_interval(diff.total_seconds(), intervals)\n",
      "            correct, pred, count = error[interval]\n",
      "            error[interval] = (correct + row.is_correct, pred + row.prediction, count + 1)\n",
      "    return error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intervals = interval_error(\n",
      "    pfat_test,\n",
      "    [(0, 0)] + [(2**x, 2**(x+1) - 1) for x in range(20)] + [(2**20, np.inf)],\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = []\n",
      "for interval, (correct, pred, count) in intervals.items():\n",
      "    result.append((\n",
      "        sum(interval) / 2.,\n",
      "        (correct - pred) / count,\n",
      "    ))\n",
      "result = sorted(result, key=lambda x: x[0])\n",
      "\n",
      "plt.plot([x[0] for x in result], [x[1] for x in result])\n",
      "plt.xscale('log')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
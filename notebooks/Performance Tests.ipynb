{
 "metadata": {
  "name": "",
  "signature": "sha256:0a8d32d32946db216ee8e80f1aec444e3157191ce2d7789190fcbf39c373258f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib qt4\n",
      "from __future__ import division\n",
      "\n",
      "from models import tools, optimize, models\n",
      "from models.tests import PerformanceTest\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = tools.load_data('../data/answers_train.csv', offset=100000, limit=50000)\n",
      "#data = data[data['number_of_options'] == 0]\n",
      "data = tools.unknown_answers(data)\n",
      "print len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12903\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elo = models.EloModel()\n",
      "#elo_test = PerformanceTest(elo, data)\n",
      "#elo_test.run()\n",
      "#print str(elo_test.rmse()) + '\\n' + str(elo_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elot = models.EloResponseTime()\n",
      "elot_test = PerformanceTest(elot, data)\n",
      "elot_test.run()\n",
      "print str(elot_test.rmse()) + '\\n' + str(elot_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.395484212707\n",
        "Training Set Size: 1392\n",
        "AUC: 0.761178225205\n",
        "Training Set Size: 1392\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfa = models.PFAModel(elo)\n",
      "pfa_test = PerformanceTest(pfa, data)\n",
      "pfa_test.run()\n",
      "print str(pfa_test.rmse()) + '\\n' + str(pfa_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.346703397122\n",
        "Training Set Size: 8492\n",
        "AUC: 0.933671069749\n",
        "Training Set Size: 8492\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "fpr, tpr, thresholds = metrics.roc_curve(pfa_test.y_true, pfa_test.y_pred, pos_label=1)\n",
      "plt.plot(fpr, tpr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f9094c67210>]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfas = models.PFASpacing(elo, decay_rate=0.18, tau=2)\n",
      "pfas_test = PerformanceTest(pfas, data)\n",
      "pfas_test.run()\n",
      "print str(pfas_test.rmse()) + '\\n' + str(pfas_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.340402920792\n",
        "Training Set Size: 8492\n",
        "AUC: 0.956092459166\n",
        "Training Set Size: 8492\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpr, tpr, thresholds = metrics.roc_curve(pfas_test.y_true, pfas_test.y_pred, pos_label=1)\n",
      "plt.plot(fpr, tpr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f3593415cd0>]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfat = models.PFATiming(elo, time_effect_fun=lambda t: 1.6 - 0.1*np.log(t))\n",
      "pfat_test = PerformanceTest(pfat, data)\n",
      "pfat_test.run()\n",
      "print str(pfat_test.rmse()) + '\\n' + str(pfat_test.auc())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 0.258370294239\n",
        "Training Set Size: 33760\n",
        "AUC: 0.819514545939\n",
        "Training Set Size: 33760\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def chunks(l, n):\n",
      "    for i in xrange(0, len(l), n):\n",
      "        yield l[i:i+n]\n",
      "\n",
      "def interval_error(test, interval_size=500):\n",
      "    answers = []\n",
      "    for id, row in test.test_set.iterrows():\n",
      "        item = test.model.items.get((row.user_id, row.place_id))\n",
      "        if item is not None and item.practices:\n",
      "            to_datetime = test.model.to_datetime\n",
      "            diff = to_datetime(row.inserted) - to_datetime(item.practices[-1])\n",
      "            answers += [(int(diff.total_seconds()), [row.is_correct, row.prediction])]\n",
      "   \n",
      "    answers = sorted(answers, key=lambda p: p[0])\n",
      "\n",
      "    get_diffs = lambda c: [diff for diff, _ in c]\n",
      "    get_answers = lambda c: [ans for _, ans in c]\n",
      "\n",
      "    intervals = {\n",
      "        (min(get_diffs(chunk)), max(get_diffs(chunk))): get_answers(chunk)\n",
      "        for chunk in chunks(answers, interval_size)\n",
      "    }\n",
      "    \n",
      "    return intervals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intervals = interval_error(pfat_test, interval_size=1500)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = []\n",
      "for interval, d in intervals.items():\n",
      "    d = np.array(d)\n",
      "    result.append((\n",
      "        sum(interval) / 2.,\n",
      "        sum(d[:, 0] - d[:, 1]) / len(d),\n",
      "    ))\n",
      "result = sorted(result, key=lambda x: x[0])\n",
      "\n",
      "plt.plot([x[0] for x in result], [x[1] for x in result])\n",
      "plt.xscale('log')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
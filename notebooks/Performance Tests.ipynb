{
 "metadata": {
  "name": "",
  "signature": "sha256:ceb3a72865d662e25ef02811e3fc91406a192088e1cdaacdc70a3646408fb3e6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib qt4\n",
      "from __future__ import division\n",
      "\n",
      "from models import tools, optimize, models, filters\n",
      "from models.tests import PerformanceTest\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn as sk\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = tools.load_data(offset=1700000, limit=100000)\n",
      "data = data[filters.africa_countries(data)]\n",
      "#data = tools.unknown_answers(data)\n",
      "print len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ST\n",
        "8815\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elo_test = PerformanceTest(models.EloModel(), data, split_data=True)\n",
      "elo_test.run()\n",
      "elo_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "RMSE: 0.401072157963\n",
        "AUC: 0.761769439159\n",
        "OFF: -0.00320089485118\n",
        "CORRECT: 1987\n",
        "ACCURACY: 0.771650485437\n",
        "Set Size: 2575"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elot_test = PerformanceTest(models.EloResponseTime(), data, split_data=True)\n",
      "elot_test.run()\n",
      "elot_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "RMSE: 0.419755451333\n",
        "AUC: 0.734505173408\n",
        "OFF: -0.0359641950947\n",
        "CORRECT: 17177\n",
        "ACCURACY: 0.737052134735\n",
        "Set Size: 23305"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfa_test = PerformanceTest(models.PFAModel(models.EloModel()), data)\n",
      "pfa_test.run()\n",
      "pfa_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "RMSE: 0.343594916471\n",
        "AUC: 0.825361038961\n",
        "OFF: 0.000243873857675\n",
        "CORRECT: 7440\n",
        "ACCURACY: 0.844015882019\n",
        "Set Size: 8815"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfag_test = PerformanceTest(models.PFAGong(models.EloModel(), gamma=1.5, delta=0., decay=0.6), data)\n",
      "pfag_test.run()\n",
      "pfag_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "RMSE: 0.347022524983\n",
        "AUC: 0.819974301456\n",
        "OFF: -0.00345776269365\n",
        "CORRECT: 7408\n",
        "ACCURACY: 0.840385706183\n",
        "Set Size: 8815"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfaf_test = PerformanceTest(models.PFAForgetting(models.EloModel()), data)\n",
      "pfaf_test.run()\n",
      "pfaf_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "RMSE: 0.345661431888\n",
        "AUC: 0.806769410847\n",
        "OFF: 0.0234006571084\n",
        "CORRECT: 7440\n",
        "ACCURACY: 0.844974446337\n",
        "Set Size: 8805"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfas_test = PerformanceTest(models.PFASpacing(models.EloModel(), iota=1.5, decay_rate=0.18), data)\n",
      "pfas_test.run()\n",
      "pfas_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "RMSE: 0.341549512208\n",
        "AUC: 0.829142975207\n",
        "OFF: 0.00363350454934\n",
        "CORRECT: 7446\n",
        "ACCURACY: 0.844696539989\n",
        "Set Size: 8815"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pfast_test = PerformanceTest(models.PFAStaircase(models.EloModel(), staircase={(-np.inf, np.inf): 5}), data)\n",
      "pfast_test.run()\n",
      "pfast_test.results['train']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "0.33809650378991235"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpr, tpr, thresholds = sk.metrics.roc_curve(\n",
      "    pfag_test.train_values['observed'],\n",
      "    pfag_test.train_values['predicted'], pos_label=1)\n",
      "plt.plot(fpr, tpr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fca9543cd50>]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positives = []\n",
      "negatives = []\n",
      "p = pfa_test.train_values[pfa_test.train_values['observed'] == 1]\n",
      "n = pfa_test.train_values[pfa_test.train_values['observed'] == 0]\n",
      "\n",
      "intervals = zip(np.arange(0, 0.99, 0.01), np.arange(0.01, 1, 0.01))\n",
      "for lower, upper in intervals:\n",
      "    positive_count = len(p[(p['predicted'] > lower) & (p['predicted'] < upper)])\n",
      "    negative_count = len(n[(n['predicted'] > lower) & (n['predicted'] < upper)])\n",
      "    positives.append(positive_count)\n",
      "    negatives.append(negative_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot([np.mean(interval) for interval in intervals], positives, 'g-')\n",
      "plt.plot([np.mean(interval) for interval in intervals], negatives, 'r-')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f1b0015b0d0>]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "65671"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}